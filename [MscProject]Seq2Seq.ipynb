{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Telescope-U/Video-Comment-Generator/blob/master/%5BMscProject%5DSeq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89805564"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "id": "89805564"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3yyKyXwYG2Y",
        "outputId": "9357cdb2-ae94-45f8-8fe3-b88a75b0a8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "id": "A3yyKyXwYG2Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKfgl4DWVrae",
        "outputId": "45f46c57-5607-44ec-b65a-916243286fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "fKfgl4DWVrae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "853e789b"
      },
      "outputs": [],
      "source": [
        "WORK_DIR = '/content/drive/MyDrive/Colab Notebooks/[Msc]Video-Comment-Generator/'\n",
        "TRAIN_FOLDER = WORK_DIR + 'Dataset/Train/'\n",
        "VALID_FOLDER = WORK_DIR + 'Dataset/Valid/'\n",
        "TEST_FOLDER = WORK_DIR + 'Dataset/Test/'\n",
        "VIDEO_PATH = WORK_DIR + 'Dataset/video_data.csv'\n",
        "COMMENT_PATH = WORK_DIR + 'Dataset/comment_data.csv'"
      ],
      "id": "853e789b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a90612b"
      },
      "source": [
        "# 1. Dataset"
      ],
      "id": "7a90612b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "288bbd13"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_ids(video_ids, train=0.7, valid=0.1, test=0.2):\n",
        "    list_copy = video_ids.copy()\n",
        "    random.shuffle(list_copy)\n",
        "    train_size = math.floor(len(list_copy)*train)\n",
        "    valid_size = math.floor(len(list_copy)*valid)\n",
        "    return list_copy[:train_size], list_copy[train_size:(train_size+valid_size)], list_copy[(train_size+valid_size):]"
      ],
      "id": "288bbd13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "002ab143"
      },
      "outputs": [],
      "source": [
        "video_df = pd.read_csv(VIDEO_PATH)\n",
        "comment_df = pd.read_csv(COMMENT_PATH)\n",
        "train_ids, valid_ids, test_ids = split_ids(video_df['vid'].unique())\n",
        "print(len(train_ids), len(valid_ids), len(test_ids))"
      ],
      "id": "002ab143"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd3f1bff"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    for i in string.punctuation:\n",
        "        text = text.replace(i, '')\n",
        "    return text.lower()\n",
        "\n",
        "video_df['title'] = video_df['title'].apply(clean_text)\n",
        "video_df['transcript'] = video_df['transcript'].apply(clean_text)\n",
        "comment_df['en_content'] = comment_df['en_content'].apply(clean_text)"
      ],
      "id": "fd3f1bff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "751dc8d5"
      },
      "outputs": [],
      "source": [
        "train_video_df = video_df[video_df['vid'].isin(train_ids)]\n",
        "valid_video_df = video_df[video_df['vid'].isin(valid_ids)]\n",
        "test_video_df = video_df[video_df['vid'].isin(test_ids)]\n",
        "\n",
        "train_comment_df = comment_df[comment_df['vid'].isin(train_ids)]\n",
        "valid_comment_df = comment_df[comment_df['vid'].isin(valid_ids)]\n",
        "test_comment_df = comment_df[comment_df['vid'].isin(test_ids)]\n",
        "\n",
        "train_comment_df.to_csv('Dataset/Train/comment.csv', index = None)\n",
        "test_comment_df.to_csv('Dataset/Test/comment.csv', index = None)\n",
        "valid_comment_df.to_csv(\"Dataset/Valid/comment.csv\", index = None)\n",
        "\n",
        "train_video_df.to_csv('Dataset/Train/video.csv', index = None)\n",
        "test_video_df.to_csv('Dataset/Test/video.csv', index = None)\n",
        "valid_video_df.to_csv(\"Dataset/Valid/video.csv\", index = None)"
      ],
      "id": "751dc8d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3510497a"
      },
      "outputs": [],
      "source": [
        "def get_data(folder):\n",
        "    comment_path = os.path.join(folder,'comment.csv')\n",
        "    video_path = os.path.join(folder,'video.csv')\n",
        "    comment_df = pd.read_csv(comment_path)\n",
        "    video_df = pd.read_csv(video_path)\n",
        "    return {'comment':comment_df, 'video': video_df}\n",
        "        "
      ],
      "id": "3510497a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "374e4e20"
      },
      "outputs": [],
      "source": [
        "train_data = get_data(TRAIN_FOLDER)\n",
        "valid_data = get_data(VALID_FOLDER)\n",
        "test_data = get_data(TEST_FOLDER)"
      ],
      "id": "374e4e20"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9ec36675",
        "outputId": "c3240e56-8234-4203-a5b7-ffa27f2f397b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                vid                                         en_content\n",
              "0       zCe72UH4Mto                                   full vlog posted\n",
              "1       zCe72UH4Mto  i knew it was impossible for you to have just ...\n",
              "2       zCe72UH4Mto  imagine if the friends that come over are like...\n",
              "3       zCe72UH4Mto                     yall own a whole grocery store\n",
              "4       zCe72UH4Mto  holy cow i cant even imagine how much the elec...\n",
              "...             ...                                                ...\n",
              "136696  _1AjMAPtmtQ  its definitely worrying that climate change is...\n",
              "136697  _1AjMAPtmtQ  last year in western oregon it was 117f or 47c...\n",
              "136698  _1AjMAPtmtQ  im fine in a dry 110115f climate but i cannot ...\n",
              "136699  _1AjMAPtmtQ  i aint seen our allies go through this of ever...\n",
              "136700  _1AjMAPtmtQ  the most powerful heatwave ever recorder in ja...\n",
              "\n",
              "[136701 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c7367ee-9c52-4ffe-b1ff-1ff73545215e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vid</th>\n",
              "      <th>en_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zCe72UH4Mto</td>\n",
              "      <td>full vlog posted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zCe72UH4Mto</td>\n",
              "      <td>i knew it was impossible for you to have just ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zCe72UH4Mto</td>\n",
              "      <td>imagine if the friends that come over are like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>zCe72UH4Mto</td>\n",
              "      <td>yall own a whole grocery store</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zCe72UH4Mto</td>\n",
              "      <td>holy cow i cant even imagine how much the elec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136696</th>\n",
              "      <td>_1AjMAPtmtQ</td>\n",
              "      <td>its definitely worrying that climate change is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136697</th>\n",
              "      <td>_1AjMAPtmtQ</td>\n",
              "      <td>last year in western oregon it was 117f or 47c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136698</th>\n",
              "      <td>_1AjMAPtmtQ</td>\n",
              "      <td>im fine in a dry 110115f climate but i cannot ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136699</th>\n",
              "      <td>_1AjMAPtmtQ</td>\n",
              "      <td>i aint seen our allies go through this of ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136700</th>\n",
              "      <td>_1AjMAPtmtQ</td>\n",
              "      <td>the most powerful heatwave ever recorder in ja...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136701 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c7367ee-9c52-4ffe-b1ff-1ff73545215e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c7367ee-9c52-4ffe-b1ff-1ff73545215e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c7367ee-9c52-4ffe-b1ff-1ff73545215e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data['comment']"
      ],
      "id": "9ec36675"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3326e42"
      },
      "source": [
        "## 1.1 Vocabulary"
      ],
      "id": "e3326e42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "390e1ce4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "specials = ['<unk>','<pad>', '<sos>', '<eos>']\n",
        "\n",
        "word_list = []\n",
        "\n",
        "def yield_tokens():\n",
        "    for data in [train_data, valid_data]:\n",
        "        columns = [data['comment']['en_content'],\n",
        "                data['video']['title'],\n",
        "                data['video']['transcript']]\n",
        "\n",
        "        token_lists = [tokenizer(str(text)) for column in columns for text in column]\n",
        "        for tokens in token_lists:\n",
        "            yield tokens\n",
        "\n",
        "vocabulary = build_vocab_from_iterator(yield_tokens(), specials=specials, min_freq=2)\n",
        "vocabulary.set_default_index(vocabulary['<unk>'])"
      ],
      "id": "390e1ce4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ada0bfcb",
        "outputId": "ecb8f836-77d7-4e0e-b3eb-9702d254f530",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50437"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(vocabulary)"
      ],
      "id": "ada0bfcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "516e9085",
        "outputId": "d4f7e08a-72c6-45d1-b56a-6c0d444c465b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 166, 198]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sentence = \"i am happy\".split()\n",
        "indexs = vocabulary.forward(sentence)\n",
        "indexs"
      ],
      "id": "516e9085"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b47d735",
        "outputId": "e9b5ae23-4f70-486f-fe1a-8cb84fe9455f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'happy']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "vocabulary.lookup_tokens(indexs)"
      ],
      "id": "2b47d735"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bcb33d1"
      },
      "source": [
        "## 1.2 Dataset & Dataloader"
      ],
      "id": "4bcb33d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c4a5675"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer=tokenizer, vocab=vocabulary, video_length=7000, comment_length = 32):\n",
        "        self.video_length = video_length\n",
        "        self.comment_length = comment_length\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "    \n",
        "        self.video_df = data['video']\n",
        "        self.comment_df = data['comment']\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        vid = self.comment_df.iloc[index]['vid']\n",
        "        \n",
        "        # trg\n",
        "        comment = str(self.comment_df.iloc[index]['en_content'])\n",
        "        tokenized_comment = self.tokenizer(comment)\n",
        "        tagged_comment = self.tag(tokenized_comment, self.comment_length)\n",
        "        comment_idxs = self.vocab.forward(tagged_comment)\n",
        "        \n",
        "        # src\n",
        "        video = self.video_df[self.video_df['vid'] == vid]\n",
        "        \n",
        "        title = str(video['title'].item())\n",
        "        transcript = str(video['transcript'].item())\n",
        "        \n",
        "        video_texts = ' '.join([title, transcript])\n",
        "        tokenized_video_texts = self.tokenizer(video_texts)[:self.video_length-2]\n",
        "        tagged_video_texts = self.tag(tokenized_video_texts, self.video_length)\n",
        "        \n",
        "        video_idxs = self.vocab.forward(tagged_video_texts)\n",
        "        \n",
        "        return torch.tensor(video_idxs).to(device), torch.tensor(comment_idxs).to(device)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.comment_df.shape[0]\n",
        "        \n",
        "    def tag(self, words, length):\n",
        "        words.insert(0, '<sos>')\n",
        "        words.append(\"<eos>\")\n",
        "        words = words + ['<pad>']*(length-len(words))\n",
        "        return words\n",
        "        "
      ],
      "id": "7c4a5675"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "372ef8fb"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_data)\n",
        "test_dataset = TextDataset(test_data)\n",
        "valid_dataset = TextDataset(valid_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n"
      ],
      "id": "372ef8fb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c039d0ec",
        "outputId": "5566d594-8da3-4cfd-e4a7-8380a2b82a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 7000]) cuda:0\n",
            "torch.Size([32, 32]) cuda:0\n"
          ]
        }
      ],
      "source": [
        "for video, comment in train_loader:\n",
        "    print(video.shape,video.device)\n",
        "    print(comment.shape,comment.device)\n",
        "    break"
      ],
      "id": "c039d0ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0be6cd0f"
      },
      "source": [
        "* `nn.Embedding(num_embedding, embedding_dim)`\n",
        "    * `num_embedding`: vocabulary_size\n",
        "    * `embedding_dim`: embedding vector size\n",
        "    * output shape : (batch_size, embedding_dim)\n",
        "* `nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)`\n",
        "    * **QUESTION**: what is the `output` of LSTM?\n",
        "        * equal to last hidden of output?\n",
        "* "
      ],
      "id": "0be6cd0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbd6f4ce"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, rnn_layers, dropout_ratio):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim) \n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, rnn_layers)\n",
        "    \n",
        "    def forward(self, src):\n",
        "        embedded_seq = self.dropout(self.embedding(src))\n",
        "        # embedded shape = (src_len ,batch_size,  embedding_dim)\n",
        "        output, (hidden, cell) = self.rnn(embedded_seq)\n",
        "        # output_shape = (seq_len, batch_size, hidden_size)\n",
        "    \n",
        "        return hidden, cell \n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embedding_dim, hidden_dim, rnn_layers,  dropout_ratio):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, rnn_layers)\n",
        "        self.fcl = nn.Linear(hidden_dim, output_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "    \n",
        "    def forward(self, trg_word, hidden, cell):\n",
        "\n",
        "        trg_seq = trg_word.unsqueeze(0) \n",
        "        # seq_len = 1\n",
        "        embedded_seq = self.dropout(self.embedding(trg_seq)) # embedded comment\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded_seq, (hidden, cell)) \n",
        "        prediction = self.fcl(output.squeeze(0)) \n",
        "        return prediction, hidden, cell\n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "id": "cbd6f4ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cec7a88e"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, vocab): \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.vocab = vocab\n",
        "    \n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "    \n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        decoder_outputs = torch.zeros(trg_len, batch_size, len(self.vocab)).to(device)\n",
        "        \n",
        "        # return final state\n",
        "        encoder_hidden, encoder_cell = self.encoder(src)\n",
        "\n",
        "        target_word = trg[0,:]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            if t == 1:\n",
        "                output, hidden, cell = self.decoder(target_word, encoder_hidden, encoder_cell)\n",
        "            else:\n",
        "                output, hidden, cell = self.decoder(target_word, hidden, cell)\n",
        "            \n",
        "            decoder_outputs[t] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            top1_word = output.argmax(1)\n",
        "            target_word = trg[t] if teacher_force else top1_word\n",
        "        \n",
        "        return decoder_outputs\n",
        "        \n",
        "        \n",
        "        "
      ],
      "id": "cec7a88e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b764746"
      },
      "source": [
        "## 2.2 Train & Evaulation"
      ],
      "id": "0b764746"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f5a74ac"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, clip, loss_fn=nn.CrossEntropyLoss()):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for video_text, comment in tqdm(loader):\n",
        "        optimizer.zero_grad()\n",
        "        video_text = video_text.permute(1,0)\n",
        "        comment = comment.permute(1,0) \n",
        "        \n",
        "        output = model(video_text, comment)\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        comment = comment[1:].contiguous().long().view(-1)\n",
        "        \n",
        "        loss = loss_fn(output, comment)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)"
      ],
      "id": "2f5a74ac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aaaf370"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader,loss_fn=nn.CrossEntropyLoss()):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for video_text, comment in tqdm(loader): \n",
        "            \n",
        "            video_text = video_text.T.contiguous()\n",
        "            comment = comment.T.contiguous() \n",
        "\n",
        "            output = model(video_text, comment)\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            comment = comment[1:].view(-1)\n",
        "\n",
        "            loss = loss_fn(output, comment)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)"
      ],
      "id": "1aaaf370"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ab7620"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "id": "b3ab7620"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f73723d"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(vocabulary)\n",
        "OUTPUT_DIM = len(vocabulary)\n",
        "\n",
        "ENCODER_EMBEDDED_DIM = 256\n",
        "DECODER_EMBEDDED_DIM = 256\n",
        "HIDDEN_DIM = 512\n",
        "NUM_LAYERS = 2\n",
        "ENCODER_DROPOUT = 0.5\n",
        "DECODER_DROPOUT = 0.5\n",
        "\n",
        "# input_dim, embedding_dim, hidden_dim, rnn_layers, dropout_ratio\n",
        "encoder = Encoder(INPUT_DIM, ENCODER_EMBEDDED_DIM, HIDDEN_DIM, NUM_LAYERS,ENCODER_DROPOUT).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM, DECODER_EMBEDDED_DIM, HIDDEN_DIM, NUM_LAYERS, DECODER_DROPOUT).to(device)\n",
        "\n",
        "# encoder, decoder, vocab\n",
        "model = Seq2Seq(encoder, decoder, vocabulary).to(device)"
      ],
      "id": "8f73723d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsqtoBsLd65E",
        "outputId": "c11f5643-4ec6-4182-d697-0358cc50124c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "model_path = os.path.join(WORK_DIR, 'Models','Seq2SeqModel2', f'epoch5.pt')\n",
        "results = torch.load(model_path)\n",
        "model.load_state_dict(results['state_dict'])"
      ],
      "id": "qsqtoBsLd65E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7256043"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "CLIP = 1\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range( EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_loader, optimizer= optimizer, clip=CLIP)\n",
        "    valid_loss = evaluate(model, valid_loader)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    result_dict = {\n",
        "        'train_loss':train_loss,\n",
        "        'valid_loss':valid_loss,\n",
        "        'state_dict': model.state_dict(),\n",
        "    }\n",
        "    torch.save(result_dict, os.path.join(WORK_DIR, 'Models','Seq2SeqModel2', f'epoch{epoch+1}.pt'))\n",
        "\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "id": "c7256043"
    },
    {
      "cell_type": "code",
      "source": [
        "class TestTextDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer=tokenizer, vocab=vocabulary, video_length=7000, comment_length = 32):\n",
        "        self.video_length = video_length\n",
        "        self.comment_length = comment_length\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "    \n",
        "        self.video_df = data['video']\n",
        "        self.comment_df = data['comment']\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        vid = self.comment_df.iloc[index]['vid']\n",
        "        \n",
        "        # trg\n",
        "        comment = str(self.comment_df.iloc[index]['en_content'])\n",
        "        tokenized_comment = self.tokenizer(comment)\n",
        "        tagged_comment = self.tag(tokenized_comment, self.comment_length)\n",
        "        comment_idxs = self.vocab.forward(tagged_comment)\n",
        "        \n",
        "        # src\n",
        "        video = self.video_df[self.video_df['vid'] == vid]\n",
        "        \n",
        "        title = str(video['title'].item())\n",
        "        transcript = str(video['transcript'].item())\n",
        "        \n",
        "        video_texts = ' '.join([title, transcript])\n",
        "        \n",
        "        tokenized_video_texts = self.tokenizer(video_texts)[:self.video_length-2]\n",
        "        text_length = self.video_length \n",
        "        \n",
        "        tagged_video_texts = self.tag(tokenized_video_texts, self.video_length)\n",
        "        \n",
        "        video_idxs = self.vocab.forward(tagged_video_texts)\n",
        "        \n",
        "        return torch.tensor(video_idxs), torch.tensor(text_length),torch.tensor(comment_idxs), vid\n",
        "        # return torch.tensor(video_idxs).to(device), torch.tensor(comment_idxs).to(device)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.comment_df.shape[0]\n",
        "        \n",
        "    def tag(self, words, length):\n",
        "        words.insert(0, '<sos>')\n",
        "        words.append(\"<eos>\")\n",
        "        words = words + ['<pad>']*(length-len(words))\n",
        "        return words\n",
        "    \n",
        "def test_collate_fn(data):\n",
        "    data.sort(key=lambda x: x[1], reverse=True) \n",
        "    video = [row[0].numpy() for row in data]\n",
        "    length = [row[1] for row in data]\n",
        "    comment = [row[2].numpy() for row in data]\n",
        "    vid = [row[3]for row in data]\n",
        "    # return torch.Tensor(video).int().to(device), torch.Tensor(length).int().to(device), torch.Tensor(comment).int().to(device)\n",
        "    return torch.Tensor(video).int().to(device), torch.Tensor(length), torch.Tensor(comment).int().to(device), vid"
      ],
      "metadata": {
        "id": "pKet_uSNfIyP"
      },
      "id": "pKet_uSNfIyP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_dataset = TestTextDataset(test_data)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, collate_fn=test_collate_fn)\n",
        "ratio = 0.5\n",
        "with torch.no_grad():\n",
        "    for video_texts, text_lens, comments, vid in tqdm(test_loader): \n",
        "        results = []\n",
        "        video_texts = video_texts.permute(1,0)\n",
        "        comments = comments.permute(1,0) # 原数据集为batch first, 因rnn需要，因此改成seq len first\n",
        "        outputs = model(video_texts, comments, ratio)\n",
        "        outputs = outputs.permute(1, 0 ,2)\n",
        "        comments = comments.permute(1, 0)\n",
        "        \n",
        "        for i in range(outputs.shape[0]):\n",
        "            generated_comment_index = outputs[i,:,:].argmax(1)\n",
        "            generated_comment = vocabulary.lookup_tokens(list(generated_comment_index))\n",
        "            generated_comment = ' '.join([word for word in generated_comment if word not in ['<pad>', '<eos>', '<sos>']])\n",
        "            comment = vocabulary.lookup_tokens(list(comments[i]))\n",
        "            comment = ' '.join([word for word in comment if word not in ['<pad>', '<eos>', '<sos>']])\n",
        "            results.append(['PadGateModel',vid[i], str(ratio), comment, generated_comment, '\\n']) \n",
        "        with open(WORK_DIR+'Models/Seq2SeqModel2/'+'predictions.csv', 'a') as f:\n",
        "            f.writelines([','.join(line) for line in results])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kOxGbgZe_QM",
        "outputId": "7a77790f-07c3-408f-854b-3428c41bcf63"
      },
      "id": "-kOxGbgZe_QM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/304 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "100%|██████████| 304/304 [10:57<00:00,  2.16s/it]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[MscProject]Seq2Seq.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:deeplearning]",
      "language": "python",
      "name": "conda-env-deeplearning-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}